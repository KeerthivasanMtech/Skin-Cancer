{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4173,"status":"ok","timestamp":1701417161545,"user":{"displayName":"KEERTHIVASAN K","userId":"14456521488650565065"},"user_tz":-330},"id":"w8JEAYISh_xy","outputId":"b5426f94-93ae-4158-eb08-22581ddc3c66"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","# Mount your Google Drive to access files\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqzk_XM3huzb"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import make_pipeline\n","from tensorflow.keras.applications import DenseNet201, MobileNetV2\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.mixed_precision import LossScaleOptimizer\n","from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess_input\n","from tensorflow.keras.applications.resnet50 import preprocess_input as mobilenet_preprocess_input\n","from sklearn.metrics import accuracy_score\n","\n","def load_images_and_labels_from_folder(folder):\n","    images = []\n","    labels = []\n","    for filename in os.listdir(folder):\n","        img = cv2.imread(os.path.join(folder, filename))\n","        if img is not None:\n","            img = cv2.resize(img, (224, 224))\n","            images.append(img)\n","            labels.append(1 if \"melanoma\" in filename else 0)\n","    return np.array(images), np.array(labels)\n","\n","# Load and preprocess images and labels\n","train_folder = '/content/drive/MyDrive/DL/sc/train'\n","test_folder = '/content/drive/MyDrive/DL/sc/test'\n","\n","X_train, y_train = load_images_and_labels_from_folder(os.path.join(train_folder, 'benign'))\n","X_melanoma, y_melanoma = load_images_and_labels_from_folder(os.path.join(train_folder, 'melanoma'))\n","\n","# Combine benign and malignant data\n","X = np.concatenate([X_train, X_melanoma])\n","y = np.concatenate([np.zeros(len(y_train)), np.ones(len(y_melanoma))])\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n","\n","# Augmentation for the training data\n","datagen = ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","datagen.fit(X_train)\n","\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","# Preprocess images for DenseNet201\n","X_train_preprocessed_densenet = densenet_preprocess_input(X_train.astype('float32'))\n","X_val_preprocessed_densenet = densenet_preprocess_input(X_val.astype('float32'))\n","X_test_preprocessed_densenet = densenet_preprocess_input(X_test.astype('float32'))\n","\n","# Preprocess images for Mobilenet\n","X_train_preprocessed_mobilenet = mobilenet_preprocess_input(X_train.astype('float32'))\n","X_val_preprocessed_mobilenet = mobilenet_preprocess_input(X_val.astype('float32'))\n","X_test_preprocessed_mobilenet = mobilenet_preprocess_input(X_test.astype('float32'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7051430,"status":"ok","timestamp":1701424253727,"user":{"displayName":"KEERTHIVASAN K","userId":"14456521488650565065"},"user_tz":-330},"id":"yyW0_QpdPrVr","outputId":"98984716-5bdf-40b9-df14-6871d0348d86"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","56/56 [==============================] - 718s 13s/step - loss: 0.5631 - accuracy: 0.7065 - val_loss: 0.4367 - val_accuracy: 0.7862\n","Epoch 2/10\n","56/56 [==============================] - 663s 12s/step - loss: 0.4484 - accuracy: 0.7941 - val_loss: 0.4016 - val_accuracy: 0.8174\n","Epoch 3/10\n","56/56 [==============================] - 758s 14s/step - loss: 0.4008 - accuracy: 0.8231 - val_loss: 0.3781 - val_accuracy: 0.8241\n","Epoch 4/10\n","56/56 [==============================] - 652s 12s/step - loss: 0.3860 - accuracy: 0.8315 - val_loss: 0.3645 - val_accuracy: 0.8352\n","Epoch 5/10\n","56/56 [==============================] - 728s 13s/step - loss: 0.3707 - accuracy: 0.8404 - val_loss: 0.3596 - val_accuracy: 0.8396\n","Epoch 6/10\n","56/56 [==============================] - 707s 13s/step - loss: 0.3671 - accuracy: 0.8304 - val_loss: 0.3601 - val_accuracy: 0.8352\n","Epoch 7/10\n","56/56 [==============================] - 659s 12s/step - loss: 0.3552 - accuracy: 0.8471 - val_loss: 0.3520 - val_accuracy: 0.8396\n","Epoch 8/10\n","56/56 [==============================] - 651s 12s/step - loss: 0.3460 - accuracy: 0.8421 - val_loss: 0.3391 - val_accuracy: 0.8508\n","Epoch 9/10\n","56/56 [==============================] - 664s 12s/step - loss: 0.3546 - accuracy: 0.8477 - val_loss: 0.3344 - val_accuracy: 0.8575\n","Epoch 10/10\n","56/56 [==============================] - 651s 12s/step - loss: 0.3389 - accuracy: 0.8538 - val_loss: 0.3326 - val_accuracy: 0.8530\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x79b55e6f2710>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Load pre-trained DenseNet201 model without the top (fully connected) layer\n","base_model_densenet = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# Freeze the layers of the pre-trained model for feature extraction\n","for layer in base_model_densenet.layers:\n","    layer.trainable = False\n","\n","# Add your own top layers for classification on top of DenseNet201\n","x_densenet = layers.GlobalAveragePooling2D()(base_model_densenet.output)\n","x_densenet = layers.Dense(512, activation='relu')(x_densenet)\n","x_densenet = layers.Dropout(0.5)(x_densenet)\n","predictions_densenet = layers.Dense(1, activation='sigmoid')(x_densenet)\n","\n","# Create the model\n","model_densenet = Model(inputs=base_model_densenet.input, outputs=predictions_densenet)\n","\n","# Compile the model\n","optimizer = Adam(learning_rate=0.0001)  # Adjust the learning rate as needed\n","optimizer = LossScaleOptimizer(optimizer)\n","model_densenet.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Use data augmentation\n","datagen = ImageDataGenerator(\n","    rotation_range=30,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,\n","    zoom_range=0.3,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","datagen.fit(X_train_preprocessed_densenet)\n","\n","# Train the model with data augmentation\n","model_densenet.fit(datagen.flow(X_train_preprocessed_densenet, y_train, batch_size=32), epochs=10, validation_data=(X_val_preprocessed_densenet, y_val))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"q3CDOIoLPuMG","outputId":"1ca81194-0600-48c1-cb63-df82a39524d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","56/56 [==============================] - 97s 2s/step - loss: 0.6303 - accuracy: 0.6769 - val_loss: 0.4830 - val_accuracy: 0.7929\n","Epoch 2/10\n","56/56 [==============================] - 86s 2s/step - loss: 0.5015 - accuracy: 0.7645 - val_loss: 0.4626 - val_accuracy: 0.7973\n","Epoch 3/10\n","56/56 [==============================] - 87s 2s/step - loss: 0.4635 - accuracy: 0.7773 - val_loss: 0.4273 - val_accuracy: 0.8218\n","Epoch 4/10\n","56/56 [==============================] - 90s 2s/step - loss: 0.4105 - accuracy: 0.8153 - val_loss: 0.4197 - val_accuracy: 0.8174\n","Epoch 5/10\n","56/56 [==============================] - 89s 2s/step - loss: 0.4044 - accuracy: 0.8225 - val_loss: 0.4204 - val_accuracy: 0.8174\n","Epoch 6/10\n","56/56 [==============================] - 87s 2s/step - loss: 0.3883 - accuracy: 0.8259 - val_loss: 0.4013 - val_accuracy: 0.8241\n","Epoch 7/10\n","56/56 [==============================] - 98s 2s/step - loss: 0.3643 - accuracy: 0.8421 - val_loss: 0.4109 - val_accuracy: 0.8330\n","Epoch 8/10\n","56/56 [==============================] - 92s 2s/step - loss: 0.3628 - accuracy: 0.8488 - val_loss: 0.4012 - val_accuracy: 0.8285\n","Epoch 9/10\n","56/56 [==============================] - 95s 2s/step - loss: 0.3452 - accuracy: 0.8538 - val_loss: 0.3867 - val_accuracy: 0.8352\n","Epoch 10/10\n","56/56 [==============================] - 94s 2s/step - loss: 0.3253 - accuracy: 0.8594 - val_loss: 0.3919 - val_accuracy: 0.8307\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x79b55f6170d0>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Load pre-trained MobileNetV2 model without the top (fully connected) layer\n","base_model_mobilenet = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# Freeze the layers of the pre-trained model for feature extraction\n","for layer in base_model_mobilenet.layers:\n","    layer.trainable = False\n","\n","# Add your own top layers for classification on top of MobileNetV2\n","x_mobilenet = layers.GlobalAveragePooling2D()(base_model_mobilenet.output)\n","x_mobilenet = layers.Dense(512, activation='relu')(x_mobilenet)\n","x_mobilenet = layers.Dropout(0.5)(x_mobilenet)\n","predictions_mobilenet = layers.Dense(1, activation='sigmoid')(x_mobilenet)\n","\n","# Create the model\n","model_mobilenet = Model(inputs=base_model_mobilenet.input, outputs=predictions_mobilenet)\n","\n","# Compile the model\n","model_mobilenet.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model_mobilenet.fit(X_train_preprocessed_mobilenet, y_train, epochs=10, batch_size=32, validation_data=(X_val_preprocessed_mobilenet, y_val))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ymCHBzT2Wooo","outputId":"90e583f2-4d55-4cf4-b3ad-8ad439166431"},"outputs":[{"name":"stdout","output_type":"stream","text":["56/56 [==============================] - 504s 9s/step\n","15/15 [==============================] - 138s 9s/step\n","13/13 [==============================] - 107s 8s/step\n","56/56 [==============================] - 75s 1s/step\n","15/15 [==============================] - 21s 1s/step\n","13/13 [==============================] - 15s 1s/step\n"]}],"source":["\n","# Extract features from DenseNet201\n","features_densenet_train = model_densenet.predict(X_train_preprocessed_densenet)\n","features_densenet_val = model_densenet.predict(X_val_preprocessed_densenet)\n","features_densenet_test = model_densenet.predict(X_test_preprocessed_densenet)\n","\n","# Extract features from MobileNetV2\n","features_mobilenet_train = model_mobilenet.predict(X_train_preprocessed_mobilenet)\n","features_mobilenet_val = model_mobilenet.predict(X_val_preprocessed_mobilenet)\n","features_mobilenet_test = model_mobilenet.predict(X_test_preprocessed_mobilenet)\n","\n","# Combine features from both models\n","X_train_combined = np.concatenate([features_densenet_train, features_mobilenet_train], axis=1)\n","X_val_combined = np.concatenate([features_densenet_val, features_mobilenet_val], axis=1)\n","X_test_combined = np.concatenate([features_densenet_test, features_mobilenet_test], axis=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GAPIRuGDhGCp","outputId":"d906018a-aba1-4221-e781-39a142ebd363"},"outputs":[{"name":"stdout","output_type":"stream","text":["Validation Accuracy: 0.8530066815144766\n","Test Accuracy: 0.8484848484848485\n"]}],"source":["\n","# Create an SVM model\n","svm_model = make_pipeline(StandardScaler(), SVC(C=1, kernel='linear', random_state=42))\n","\n","# Fit the SVM model on the training data\n","svm_model.fit(X_train_combined, y_train)\n","\n","# Predict on the validation set\n","y_val_pred = svm_model.predict(X_val_combined)\n","\n","# Evaluate accuracy on the validation set\n","accuracy_val = accuracy_score(y_val, y_val_pred)\n","print(f\"Validation Accuracy: {accuracy_val}\")\n","\n","# Predict on the test set\n","y_test_pred = svm_model.predict(X_test_combined)\n","\n","# Evaluate accuracy on the test set\n","accuracy_test = accuracy_score(y_test, y_test_pred)\n","print(f\"Test Accuracy: {accuracy_test}\")"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPkxIOOhkHem7+NQXFz4Ikd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}